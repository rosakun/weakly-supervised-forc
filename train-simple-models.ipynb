{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FoRC4CL import FoRC4CLData\n",
    "from utils.utils import get_all_labels\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,  VotingClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress an annoying warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"Label not .* is present in all training examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trains and tests basic ML models on the FoRC4CL train/test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got FoRC4CL data\n",
      "Got FoRC4CL data\n",
      "Got training and testing data.\n"
     ]
    }
   ],
   "source": [
    "# Get the training and testing data + labels\n",
    "data_train = FoRC4CLData(forc4cl_data_path=\"data/forc4cl_fulltext/train_fulltext.csv\")\n",
    "data_test = FoRC4CLData(forc4cl_data_path=\"data/forc4cl_fulltext/test_fulltext.csv\")\n",
    "\n",
    "X_train = data_train._get_documents(lowercase=True,stem=True)\n",
    "y_train = data_train._get_labels()\n",
    "\n",
    "X_test = data_test._get_documents(lowercase=True,stem=True)\n",
    "y_test = data_test._get_labels()\n",
    "\n",
    "print(\"Got training and testing data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is vectorized.\n"
     ]
    }
   ],
   "source": [
    "# Tfidf-vectorize the training and testing data\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Data is vectorized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise the classifier. Initialise multiple classifiers if using an ensemble later\n",
    "clf1 = OneVsRestClassifier(LogisticRegression(class_weight='balanced',solver='liblinear',penalty='l1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 1 initialized.\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier. Again, train multiple classifiers if using an ensemble later\n",
    "clf1.fit(X_train_tfidf, y_train)\n",
    "print(\"Classifier initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions have been made by classifier 1.\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_1 = clf1.predict(X_test_tfidf)\n",
    "print(\"Predictions have been made by classifier 1.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following two cells define and run a majority voting ensemble using as many models as you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(predictions, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Perform majority voting on multi-label predictions.\n",
    "    \n",
    "    :param predictions: List of numpy arrays of shape (num_samples, num_labels)\n",
    "                        Each array is a modelâ€™s binary predictions.\n",
    "    :param threshold: Fraction of models that must predict 1 for the final vote.\n",
    "                      Default is 0.5 (majority voting).\n",
    "    :return: Final ensemble predictions (numpy array of shape (num_samples, num_labels))\n",
    "    \"\"\"\n",
    "    predictions = np.array(predictions)  # Shape: (num_models, num_samples, num_labels)\n",
    "    vote_counts = np.sum(predictions, axis=0)  # Sum over models, shape: (num_samples, num_labels)\n",
    "    \n",
    "    # Apply threshold: If more than (threshold * num_models) models predict 1, assign 1\n",
    "    num_models = predictions.shape[0]\n",
    "    final_predictions = (vote_counts >= (threshold * num_models)).astype(int)\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Create ensemble predictions\n",
    "y_pred = majority_voting([y_pred_1, y_pred_2, y_pred_3], threshold=0.4)\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                                                     precision    recall  f1-score   support\n",
      "\n",
      "             Abstract Meaning Representation (AMR)       0.00      0.00      0.00         0\n",
      "                    Abstractive Text Summarization       1.00      1.00      1.00         1\n",
      "Acronyms and Abbreviations Detection and Expansion       0.00      0.00      0.00         0\n",
      "                                   Active Learning       0.00      0.00      0.00         1\n",
      "                Adversarial Attacks and Robustness       1.00      1.00      1.00         2\n",
      "                              Adversarial Learning       0.50      0.33      0.40         3\n",
      "                               Anaphora Resolution       0.00      0.00      0.00         1\n",
      "                              Annotation Processes       0.46      0.30      0.36        20\n",
      "                                   Argument Mining       1.00      1.00      1.00         2\n",
      "                            Aspect-Based SA (ABSA)       0.00      0.00      0.00         0\n",
      "                   Audio Generation and Processing       0.50      0.25      0.33         4\n",
      "                                  Author Detection       0.00      0.00      0.00         0\n",
      "                           Authorship Verification       0.00      0.00      0.00         0\n",
      "                           Automated Essay Scoring       0.00      0.00      0.00         0\n",
      "                Automatic Speech Recognition (ASR)       0.50      0.50      0.50         2\n",
      "                      Automatic Text Summarization       0.75      0.75      0.75         4\n",
      "                                  Backdoor Attacks       0.00      0.00      0.00         0\n",
      "                                    Bias Detection       0.00      0.00      0.00         1\n",
      "                                     Biases in NLP       1.00      0.33      0.50         6\n",
      "                 Bilingual Lexicon Induction (BLI)       0.00      0.00      0.00         3\n",
      "                                    Biomedical NLP       1.00      0.86      0.92         7\n",
      "                    Causality Relations Extraction       0.00      0.00      0.00         1\n",
      "                                          Chatbots       0.00      0.00      0.00         3\n",
      "                                 Citation Analysis       0.00      0.00      0.00         0\n",
      "                                Claim Verification       0.00      0.00      0.00         2\n",
      "                       Classification Applications       0.71      0.62      0.66        55\n",
      "                             Commonsense Reasoning       0.00      0.00      0.00         1\n",
      "                                      Community QA       0.00      0.00      0.00         3\n",
      "                              Constituency Parsing       0.67      1.00      0.80         2\n",
      "                            Coreference Resolution       0.80      0.80      0.80         5\n",
      "                         Cross-lingual Application       0.50      0.43      0.46         7\n",
      "                                     Data Analysis       0.33      0.12      0.18        24\n",
      "                                 Data Augmentation       0.75      0.46      0.57        13\n",
      "                    Data Management and Generation       0.66      0.53      0.59        91\n",
      "                                  Data Preparation       0.70      0.43      0.54        60\n",
      "                           Data-to-Text Generation       0.00      0.00      0.00         0\n",
      "                                Dependency Parsing       0.44      0.40      0.42        10\n",
      "                     Dialogue State Tracking (DST)       0.00      0.00      0.00         0\n",
      "                                  Dialogue Systems       0.00      0.00      0.00         5\n",
      "                                Discourse Analysis       0.67      0.33      0.44         6\n",
      "                                 Discourse Parsing       0.00      0.00      0.00         3\n",
      "                              Disfluency Detection       0.00      0.00      0.00         0\n",
      "                    Document Layout Analysis (DLA)       0.00      0.00      0.00         0\n",
      "                            Document Summarization       0.00      0.00      0.00         2\n",
      "                               Domain-specific NLP       0.80      0.35      0.49        68\n",
      "                 Email Spam and Phishing Detection       0.00      0.00      0.00         0\n",
      "                                        Embeddings       0.60      0.46      0.52        13\n",
      "                                 Emotion Detection       0.67      0.67      0.67         3\n",
      "                                    Entity Linking       0.00      0.00      0.00         1\n",
      "                    Error Detection and Correction       1.00      0.33      0.50         6\n",
      "                                            Ethics       0.00      0.00      0.00        10\n",
      "                             Evaluation Techniques       0.40      0.14      0.21        14\n",
      "                                  Event Extraction       1.00      0.20      0.33         5\n",
      "               Explainability and Interpretability       0.00      0.00      0.00         0\n",
      "                     Extractive Text Summarization       0.00      0.00      0.00         3\n",
      "                               Fake News Detection       0.00      0.00      0.00         0\n",
      "                             Fake Review Detection       0.00      0.00      0.00         0\n",
      "                                 Few-shot Learning       0.00      0.00      0.00         2\n",
      "                               Figurative Language       0.00      0.00      0.00         0\n",
      "                             Finite State Machines       0.00      0.00      0.00         0\n",
      "                                       Gender Bias       0.00      0.00      0.00         2\n",
      "                Grammatical Error Correction (GEC)       0.50      0.50      0.50         2\n",
      "                      Graph Neural Networks (GNNs)       0.00      0.00      0.00         2\n",
      "               Hate and Offensive Speech Detection       1.00      0.80      0.89         5\n",
      "                             Hope Speech Detection       0.00      0.00      0.00         0\n",
      "                         Human-machine Interaction       0.00      0.00      0.00         0\n",
      "                                   Humor Detection       0.00      0.00      0.00         0\n",
      "                              Hypernymy Extraction       0.00      0.00      0.00         0\n",
      "                             Idiomatic Expressions       0.00      0.00      0.00         0\n",
      "                                  Image Captioning       0.00      0.00      0.00         2\n",
      "                        Image and Video Processing       0.60      0.50      0.55         6\n",
      "                            Information Extraction       0.66      0.64      0.65        33\n",
      "                             Information Filtering       0.00      0.00      0.00         2\n",
      "                             Information Retrieval       0.80      0.57      0.67         7\n",
      "            Infrastructure or Platform Development       0.00      0.00      0.00         0\n",
      "                                Intelligent Agents       0.00      0.00      0.00         0\n",
      "                                  Intent Detection       0.00      0.00      0.00         2\n",
      "                                   Irony Detection       0.00      0.00      0.00         0\n",
      "                                 Knowledge Base QA       0.00      0.00      0.00         0\n",
      "                                  Knowledge Graphs       1.00      0.50      0.67         2\n",
      "            Knowledge Representation and Reasoning       1.00      0.19      0.32        21\n",
      "                          Language Change Analysis       0.00      0.00      0.00         2\n",
      "                      Large Language Models (LLMs)       0.00      0.00      0.00         2\n",
      "                 Latent Dirichlet Allocation (LDA)       0.00      0.00      0.00         0\n",
      "                                Learning Paradigms       0.75      0.45      0.57        66\n",
      "                                   Link Prediction       0.00      0.00      0.00         1\n",
      "                                      Long Form QA       0.00      0.00      0.00         0\n",
      "              Long Short-Term Memory (LSTM) Models       0.50      0.08      0.13        13\n",
      "                            Low-resource Languages       0.92      0.72      0.80        92\n",
      "                                 Lyrics Generation       0.00      0.00      0.00         0\n",
      "                          Machine Translation (MT)       0.94      0.71      0.81        21\n",
      "                                   Mathematical QA       0.00      0.00      0.00         0\n",
      "                          Medical and Clinical NLP       0.79      0.44      0.56        25\n",
      "                                         Metaphors       0.00      0.00      0.00         0\n",
      "                          Misinformation Detection       0.50      0.33      0.40         3\n",
      "                               Model Architectures       0.79      0.69      0.74        78\n",
      "                             Morphological Parsing       0.00      0.00      0.00         1\n",
      "                 Multi-agent Communication Systems       0.00      0.00      0.00         0\n",
      "                      Multi-document Summarization       0.00      0.00      0.00         0\n",
      "                                Multihop Reasoning       0.00      0.00      0.00         0\n",
      "                    Multilabel Text Classification       0.00      0.00      0.00         2\n",
      "                                  Multilingual NLP       0.53      0.35      0.42        23\n",
      "                               Multimodal Learning       0.88      0.70      0.78        10\n",
      "                         Multiple Choice QA (MCQA)       0.00      0.00      0.00         0\n",
      "                           NER for Nested Entities       0.00      0.00      0.00         0\n",
      "                                      NLP for Arts       0.00      0.00      0.00         0\n",
      "          NLP for Bibliometrics and Scientometrics       0.00      0.00      0.00         3\n",
      "                                   NLP for Climate       0.00      0.00      0.00         0\n",
      "                                 NLP for Education       0.00      0.00      0.00         0\n",
      "                                   NLP for Finance       1.00      0.50      0.67         2\n",
      "                                NLP for Literature       0.00      0.00      0.00         0\n",
      "                             NLP for Mental Health       1.00      0.33      0.50         3\n",
      "                                     NLP for Music       0.00      0.00      0.00         0\n",
      "                            NLP for News and Media       0.83      0.52      0.64        29\n",
      "                                  NLP for Politics       0.00      0.00      0.00         0\n",
      "                              NLP for Social Media       0.88      0.68      0.77        22\n",
      "                          NLP for the Legal Domain       0.00      0.00      0.00         1\n",
      "                    Named Entity Recognition (NER)       0.50      0.17      0.25         6\n",
      "                    Narrative Plot in Storytelling       0.00      0.00      0.00         0\n",
      "                  Natural Language Inference (NLI)       0.00      0.00      0.00         0\n",
      "                                   Neural MT (NMT)       0.88      0.70      0.78        10\n",
      "                                        Ontologies       0.00      0.00      0.00         0\n",
      "                             Ontology Construction       0.00      0.00      0.00         0\n",
      "                                Ontology Extension       0.00      0.00      0.00         0\n",
      "                                 Ontology Matching       0.00      0.00      0.00         0\n",
      "                      Open Domain Dialogue Systems       0.00      0.00      0.00         0\n",
      "                                    Open-Domain QA       0.00      0.00      0.00         0\n",
      "               Optical Character Recognition (OCR)       0.00      0.00      0.00         0\n",
      "                Paraphrase and Rephrase Generation       0.00      0.00      0.00         0\n",
      "                                           Parsing       0.94      0.65      0.77        23\n",
      "                      Part-of-Speech (POS) Tagging       0.00      0.00      0.00         2\n",
      "                      Personality Trait Prediction       0.00      0.00      0.00         1\n",
      "                              Plagiarism Detection       0.00      0.00      0.00         0\n",
      "                                 Poetry Generation       0.00      0.00      0.00         0\n",
      "                                Prompt Engineering       0.00      0.00      0.00         0\n",
      "                           Question Answering (QA)       0.82      0.69      0.75        13\n",
      "                               Recommender Systems       0.00      0.00      0.00         2\n",
      "                  Recurrent Neural Networks (RNNs)       0.75      0.20      0.32        15\n",
      "                            Reinforcement Learning       0.00      0.00      0.00         5\n",
      "                               Relation Extraction       1.00      0.60      0.75         5\n",
      "                               Response Generation       0.00      0.00      0.00         1\n",
      "                                          Robotics       0.00      0.00      0.00         0\n",
      "                              Rule-based MT (RBMT)       0.00      0.00      0.00         0\n",
      "                                   Rumor Detection       0.00      0.00      0.00         0\n",
      "                                 Sarcasm Detection       1.00      1.00      1.00         2\n",
      "                 Scientific Document Summarization       0.00      0.00      0.00         0\n",
      "                                    Search Engines       0.00      0.00      0.00         0\n",
      "                          Semantic Change Analysis       0.00      0.00      0.00         0\n",
      "                                  Semantic Parsing       0.67      0.33      0.44         6\n",
      "                            Semantic Role Labeling       0.00      0.00      0.00         2\n",
      "                                      Semantic Web       0.00      0.00      0.00         0\n",
      "                               Sentence Embeddings       0.00      0.00      0.00         0\n",
      "                             Sentence Segmentation       0.00      0.00      0.00         0\n",
      "                           Sentiment Analysis (SA)       0.75      0.38      0.50         8\n",
      "      Sign Language and Fingerspelling Recognition       0.00      0.00      0.00         1\n",
      "                              Software Development       0.00      0.00      0.00         0\n",
      "                                  Speech Synthesis       0.00      0.00      0.00         1\n",
      "                                  Stance Detection       0.00      0.00      0.00         1\n",
      "                              Statistical MT (SMT)       0.00      0.00      0.00         4\n",
      "                                  Story Generation       0.00      0.00      0.00         0\n",
      "                               Supervised Learning       0.00      0.00      0.00        16\n",
      "                                 Syntactic Parsing       0.60      0.82      0.69        11\n",
      "                          Table-to-Text Generation       0.00      0.00      0.00         0\n",
      "                             Taxonomy Construction       0.00      0.00      0.00         0\n",
      "                      Temporal Event Understanding       0.00      0.00      0.00         0\n",
      "                                   Text Clustering       0.00      0.00      0.00         1\n",
      "                                   Text Generation       0.46      0.50      0.48        12\n",
      "                                Text Preprocessing       0.00      0.00      0.00         7\n",
      "                                 Text Segmentation       0.00      0.00      0.00         5\n",
      "                               Text Simplification       1.00      0.25      0.40         4\n",
      "                               Text Style Transfer       0.00      0.00      0.00         0\n",
      "                                       Text-to-SQL       0.00      0.00      0.00         1\n",
      "                                    Topic Modeling       0.00      0.00      0.00         1\n",
      "                                 Transfer Learning       0.60      0.27      0.38        11\n",
      "                                Transformer Models       0.47      0.25      0.33        28\n",
      "                             Unsupervised Learning       0.67      0.75      0.71         8\n",
      "                                  Video Captioning       0.00      0.00      0.00         0\n",
      "                                   Visual QA (VQA)       1.00      0.50      0.67         2\n",
      "                                   Word Embeddings       0.33      0.22      0.27         9\n",
      "                                 Word Segmentation       0.00      0.00      0.00         2\n",
      "                   Word Sense Disambiguation (WSD)       1.00      1.00      1.00         1\n",
      "\n",
      "                                         micro avg       0.71      0.45      0.55      1187\n",
      "                                         macro avg       0.26      0.18      0.21      1187\n",
      "                                      weighted avg       0.66      0.45      0.52      1187\n",
      "                                       samples avg       0.68      0.46      0.52      1187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print evaluations\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=get_all_labels()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate weakly labeled predictions for the ACL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns a prediction vector into a list of labels\n",
    "def vector_to_label_list(predictions):\n",
    "    labels = []\n",
    "    for i in range(len(predictions)):\n",
    "        pred = predictions[i]\n",
    "        to_labels = [get_all_labels()[j] for j in range(len(pred)) if pred[j] == 1]\n",
    "        labels.append(to_labels)\n",
    "    return labels\n",
    "\n",
    "# Unflatten a list of labels\n",
    "def sort_predictions_in_hierarchy(predictions):\n",
    "    level1labels, level2labels, level3labels = get_all_labels(level='lvl1'), get_all_labels(level='lvl2'), get_all_labels(level='lvl3')\n",
    "    hierarchical_predictions = []\n",
    "    for prediction in predictions:\n",
    "        level1 = []\n",
    "        level2 = []\n",
    "        level3 = []\n",
    "        for label in prediction:\n",
    "            if label in level1labels:\n",
    "                level1.append(label)\n",
    "            elif label in level2labels:\n",
    "                level2.append(label)\n",
    "            elif label in level3labels:\n",
    "                level3.append(label)\n",
    "        prediction_hierarchical = [level1, level2, level3]\n",
    "        hierarchical_predictions.append(prediction_hierarchical)\n",
    "    return hierarchical_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got FoRC4CL data\n",
      "Got FoRC4CL data\n",
      "Got training documents\n",
      "Got training labels\n",
      "Got training and testing data.\n"
     ]
    }
   ],
   "source": [
    "# Get the training data and the data to label.\n",
    "# This code takes 6 minutes to run.\n",
    "data_train = FoRC4CLData(forc4cl_data_path=\"data/forc4cl_fulltext/train_fulltext.csv\")\n",
    "data_test = FoRC4CLData(forc4cl_data_path=\"data/acl/acl_with_fulltext.csv\") #acl data can be processed with FoRC4CLData because the formatting is the same\n",
    "\n",
    "X_train = data_train._get_documents(lowercase=True,stem=True,full_text=False)\n",
    "print(\"Got training documents\")\n",
    "y_train = data_train._get_labels()\n",
    "print(\"Got training labels\")\n",
    "\n",
    "# y_test is not needed as it is used only for evaluation\n",
    "X_test = data_test._get_documents(lowercase=True,stem=True)\n",
    "print(\"Got training and testing data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is vectorized.\n"
     ]
    }
   ],
   "source": [
    "# Tfidf-vectorize the training and testing data\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Data is vectorized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the classifier\n",
    "#classifier = OneVsRestClassifier(LogisticRegression(class_weight='balanced'))\n",
    "classifier = OneVsRestClassifier(LogisticRegression(class_weight='balanced',solver='liblinear',penalty='l1'))\n",
    "#classifier = OneVsRestClassifier(SGDClassifier(class_weight='balanced'))\n",
    "#classifier = OneVsRestClassifier(RandomForestClassifier(class_weight='balanced'))\n",
    "#classifier = OneVsRestClassifier(SVC(class_weight='balanced',kernel='linear',probability=True))\n",
    "#classifier = XGBClassifier(n_estimators = 2, max_depth=8, learning_rate=1, objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier initialized.\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "print(\"Classifier initialized.\")\n",
    "\n",
    "# If you want to use a model ensemble, copy the relevant code from the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions have been made.\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "print(\"Predictions have been made.\")\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the predictions to get hierarchical labels\n",
    "# This code runs for 4-5 minutes.\n",
    "labels = vector_to_label_list(y_pred)\n",
    "hierarchical_labels = sort_predictions_in_hierarchy(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new file with the predictions\n",
    "data_test._write_predictions_to_new_file(hierarchical_labels, \"preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to the formatting required for the FoRC CodaBench competition\n",
    "df = pd.read_csv(\"preds.csv\")\n",
    "\n",
    "new_df = df[['data_index', 'Level1', 'Level2', 'Level3']]\n",
    "new_df = new_df.rename(columns={'Level1': 'Level1_pred', 'Level2': 'Level2_pred', 'Level3': 'Level3_pred'})\n",
    "\n",
    "new_df.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the weakly supervised dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got FoRC4CL data\n"
     ]
    }
   ],
   "source": [
    "# Load the file with predictions\n",
    "finished_data = FoRC4CLData(\"acl_predictions/acl_logisticregression_preds_with_fulltext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes missing: 40\n",
      "['Acronyms and Abbreviations Detection and Expansion', 'Annotation Processes', 'Aspect-Based SA (ABSA)', 'Backdoor Attacks', 'Biomedical NLP', 'Causality Relations Extraction', 'Citation Analysis', 'Constituency Parsing', 'Dependency Parsing', 'Disfluency Detection', 'Explainability and Interpretability', 'Fake News Detection', 'Fake Review Detection', 'Human-machine Interaction', 'Infrastructure or Platform Development', 'Irony Detection', 'Long Short-Term Memory (LSTM) Models', 'Multi-document Summarization', 'NER for Nested Entities', 'NLP for Arts', 'NLP for Climate', 'NLP for Education', 'NLP for Literature', 'NLP for Mental Health', 'NLP for Music', 'NLP for Politics', 'NLP for Social Media', 'Narrative Plot in Storytelling', 'Natural Language Inference (NLI)', 'Ontology Construction', 'Ontology Extension', 'Ontology Matching', 'Recommender Systems', 'Robotics', 'Scientific Document Summarization', 'Semantic Role Labeling', 'Sentence Segmentation', 'Software Development', 'Table-to-Text Generation', 'Word Segmentation']\n"
     ]
    }
   ],
   "source": [
    "finished_data._count_missingclasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 41107\n",
      "Author Detection: 2\n",
      "Speech Synthesis: 3\n",
      "Idiomatic Expressions: 4\n",
      "Scientific Document Summarization: 4\n",
      "Ontology Construction: 9\n",
      "Email Spam and Phishing Detection: 14\n",
      "Long Form QA: 21\n",
      "Lyrics Generation: 23\n",
      "NER for Nested Entities: 30\n",
      "Narrative Plot in Storytelling: 31\n",
      "Mathematical QA: 32\n",
      "Causality Relations Extraction: 33\n",
      "Hope Speech Detection: 35\n",
      "Fake Review Detection: 39\n",
      "Authorship Verification: 50\n",
      "Automated Essay Scoring: 51\n",
      "Hypernymy Extraction: 52\n",
      "Latent Dirichlet Allocation (LDA): 55\n",
      "Poetry Generation: 57\n",
      "Rumor Detection: 61\n",
      "Optical Character Recognition (OCR): 62\n",
      "Story Generation: 74\n",
      "Table-to-Text Generation: 82\n",
      "Citation Analysis: 84\n",
      "Anaphora Resolution: 86\n",
      "Plagiarism Detection: 97\n",
      "Sign Language and Fingerspelling Recognition: 99\n",
      "Text-to-SQL: 105\n",
      "Recommender Systems: 110\n",
      "Multi-agent Communication Systems: 116\n",
      "Intelligent Agents: 116\n",
      "Multihop Reasoning: 116\n",
      "Personality Trait Prediction: 118\n",
      "Multiple Choice QA (MCQA): 133\n",
      "Video Captioning: 136\n",
      "Sentence Segmentation: 150\n",
      "Dialogue State Tracking (DST): 154\n",
      "Sarcasm Detection: 158\n",
      "Open Domain Dialogue Systems: 169\n",
      "Metaphors: 178\n",
      "Abstract Meaning Representation (AMR): 184\n",
      "Figurative Language: 190\n",
      "Document Layout Analysis (DLA): 203\n",
      "Semantic Change Analysis: 213\n",
      "Humor Detection: 214\n",
      "NLP for the Legal Domain: 215\n",
      "Fake News Detection: 216\n",
      "Stance Detection: 222\n",
      "Taxonomy Construction: 232\n",
      "Bias Detection: 234\n",
      "Search Engines: 239\n",
      "Active Learning: 243\n",
      "Intent Detection: 248\n",
      "Text Style Transfer: 263\n",
      "Semantic Web: 263\n",
      "Constituency Parsing: 267\n",
      "Finite State Machines: 277\n",
      "Prompt Engineering: 289\n",
      "Sentence Embeddings: 293\n",
      "Large Language Models (LLMs): 299\n",
      "Ontology Extension: 304\n",
      "Knowledge Base QA: 307\n",
      "NLP for Finance: 340\n",
      "Visual QA (VQA): 346\n",
      "Entity Linking: 357\n",
      "Claim Verification: 364\n",
      "Text Simplification: 365\n",
      "Gender Bias: 382\n",
      "Misinformation Detection: 384\n",
      "Language Change Analysis: 416\n",
      "Information Filtering: 417\n",
      "Bilingual Lexicon Induction (BLI): 431\n",
      "Rule-based MT (RBMT): 443\n",
      "Image Captioning: 448\n",
      "Link Prediction: 485\n",
      "Adversarial Attacks and Robustness: 503\n",
      "Ontologies: 551\n",
      "Open-Domain QA: 573\n",
      "Temporal Event Understanding: 586\n",
      "NLP for Bibliometrics and Scientometrics: 600\n",
      "Grammatical Error Correction (GEC): 608\n",
      "Word Sense Disambiguation (WSD): 614\n",
      "Discourse Parsing: 617\n",
      "Paraphrase and Rephrase Generation: 627\n",
      "Emotion Detection: 630\n",
      "Morphological Parsing: 634\n",
      "Reinforcement Learning: 637\n",
      "Adversarial Learning: 652\n",
      "Argument Mining: 667\n",
      "Word Segmentation: 681\n",
      "Coreference Resolution: 683\n",
      "Chatbots: 685\n",
      "Text Clustering: 694\n",
      "Aspect-Based SA (ABSA): 706\n",
      "Semantic Role Labeling: 710\n",
      "Community QA: 723\n",
      ": 729\n",
      "Hate and Offensive Speech Detection: 729\n",
      "Extractive Text Summarization: 744\n",
      "NLP for Mental Health: 759\n",
      "Part-of-Speech (POS) Tagging: 795\n",
      "Biomedical NLP: 798\n",
      "Few-shot Learning: 800\n",
      "Document Summarization: 800\n",
      "Commonsense Reasoning: 826\n",
      "Event Extraction: 858\n",
      "Response Generation: 860\n",
      "Data-to-Text Generation: 927\n",
      "Abstractive Text Summarization: 989\n",
      "Biases in NLP: 1034\n",
      "Topic Modeling: 1052\n",
      "Graph Neural Networks (GNNs): 1105\n",
      "Text Segmentation: 1124\n",
      "Multimodal Learning: 1141\n",
      "Error Detection and Correction: 1216\n",
      "Automatic Speech Recognition (ASR): 1228\n",
      "Ethics: 1269\n",
      "Knowledge Graphs: 1282\n",
      "Discourse Analysis: 1308\n",
      "Automatic Text Summarization: 1382\n",
      "Multilabel Text Classification: 1428\n",
      "Image and Video Processing: 1778\n",
      "Dependency Parsing: 1896\n",
      "Information Retrieval: 1925\n",
      "Relation Extraction: 1995\n",
      "Text Preprocessing: 2183\n",
      "Transfer Learning: 2225\n",
      "Medical and Clinical NLP: 2357\n",
      "Question Answering (QA): 2363\n",
      "Syntactic Parsing: 2385\n",
      "Sentiment Analysis (SA): 2393\n",
      "Named Entity Recognition (NER): 2416\n",
      "Audio Generation and Processing: 2444\n",
      "Semantic Parsing: 2526\n",
      "Dialogue Systems: 2612\n",
      "Unsupervised Learning: 2632\n",
      "Statistical MT (SMT): 2697\n",
      "Cross-lingual Application: 2816\n",
      "Data Augmentation: 2967\n",
      "Word Embeddings: 3587\n",
      "NLP for Social Media: 3810\n",
      "Parsing: 4263\n",
      "Neural MT (NMT): 4339\n",
      "Long Short-Term Memory (LSTM) Models: 4350\n",
      "Embeddings: 4465\n",
      "Text Generation: 4494\n",
      "Evaluation Techniques: 4795\n",
      "NLP for News and Media: 5096\n",
      "Machine Translation (MT): 5469\n",
      "Multilingual NLP: 5517\n",
      "Transformer Models: 5614\n",
      "Knowledge Representation and Reasoning: 5818\n",
      "Recurrent Neural Networks (RNNs): 6159\n",
      "Supervised Learning: 6222\n",
      "Annotation Processes: 6290\n",
      "Information Extraction: 7054\n",
      "Data Analysis: 7914\n",
      "Domain-specific NLP: 9041\n",
      "Classification Applications: 9983\n",
      "Learning Paradigms: 10733\n",
      "Data Preparation: 12017\n",
      "Model Architectures: 15195\n",
      "Low-resource Languages: 15592\n",
      "Data Management and Generation: 16316\n"
     ]
    }
   ],
   "source": [
    "finished_data._count_instances_per_class()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

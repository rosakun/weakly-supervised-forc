{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDZZOelRNuXj",
        "outputId": "8b6d0039-897a-4381-c383-250c3d13d050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (17.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.11/dist-packages (from pyarrow) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukOBFyRhvSYq",
        "outputId": "ae7a0d63-b9a2-495d-e58a-3ee836051322"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1QAwWJv7PZJ",
        "outputId": "a59b4235-006d-4439-a83a-0efcc4ad09a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "k2kWO1Gy7TeF"
      },
      "outputs": [],
      "source": [
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from datasets import DatasetDict\n",
        "#from datasets import load_metric\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, get_scheduler\n",
        "from transformers import DebertaTokenizer, XLNetTokenizer,XLNetModel\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import zipfile\n",
        "import sys\n",
        "\n",
        "import ast\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "kzWM68MivV_g",
        "outputId": "337cf1c0-870a-4144-dd81-cc4253ecb967"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250216_124929-kemhaw5m</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rosakun/forc3cl/runs/kemhaw5m' target=\"_blank\">deepset/roberta-base-squad2</a></strong> to <a href='https://wandb.ai/rosakun/forc3cl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rosakun/forc3cl' target=\"_blank\">https://wandb.ai/rosakun/forc3cl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rosakun/forc3cl/runs/kemhaw5m' target=\"_blank\">https://wandb.ai/rosakun/forc3cl/runs/kemhaw5m</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rosakun/forc3cl/runs/kemhaw5m?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x78c613c58410>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "model_name = 'deepset/roberta-base-squad2'\n",
        "wandb.init(project=\"forc3cl\", name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "1g0Jzuz67X2_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "qrKaJtf7cpXK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdmDX_xO9XgC"
      },
      "source": [
        "## Get data - transform into one-hot encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "4oEGxlH37goS"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('deepset/roberta-base-squad2')\n",
        "#tokenizer = DebertaTokenizer.from_pretrained(\"microsoft/deberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "smMlwXZR7p5Y"
      },
      "outputs": [],
      "source": [
        "# for this example, only metadata of title and abstract will be used\n",
        "data = pd.read_csv('train_doi.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "yGjxeB7c77BP"
      },
      "outputs": [],
      "source": [
        "data = data[['title', 'abstract', 'Level1', 'Level2', 'Level3']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URgM-ioU8DJB",
        "outputId": "4271a905-55a4-4d9e-991f-65ae5733f383"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-71-453bdeef6c6c>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['abstract'] = [\"\" if pd.isna(abstract) else abstract for abstract in data['abstract']]\n",
            "<ipython-input-71-453bdeef6c6c>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = [row['title'] + tokenizer.sep_token + (row['abstract'] or '')\n"
          ]
        }
      ],
      "source": [
        "# remove nan from abstracts\n",
        "data['abstract'] = [\"\" if pd.isna(abstract) else abstract for abstract in data['abstract']]\n",
        "# Get text\n",
        "data['text'] = [row['title'] + tokenizer.sep_token + (row['abstract'] or '')\n",
        "                    for index, row in data.iterrows()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "3hMBWegy8GtQ"
      },
      "outputs": [],
      "source": [
        "# In this example, we will disregard the hierarchical structure of each level\n",
        "all_labels = []\n",
        "for idx, row in data.iterrows():\n",
        "    labels = []\n",
        "    level1 = ast.literal_eval(row['Level1'])\n",
        "    labels.append(level1)\n",
        "\n",
        "    if type(row['Level2']) != float:\n",
        "        level2 = ast.literal_eval(row['Level2'])\n",
        "        labels.append(level2)\n",
        "\n",
        "    if type(row['Level3']) != float:\n",
        "        level3 = ast.literal_eval(row['Level3'])\n",
        "        labels.append(level3)\n",
        "\n",
        "    labels_flat = [item for items in labels for item in items]\n",
        "\n",
        "    all_labels.append(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFVo_B1P8K1D",
        "outputId": "5f0fbf4f-d1c5-45b0-b696-d36442981a46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-73-6f788cda79c8>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['labels'] = all_labels\n"
          ]
        }
      ],
      "source": [
        "data['labels'] = all_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gjWB9vFq8QPl",
        "outputId": "9142631f-ea26-4dd4-fe3a-36ea4bfcf3f3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1050,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1050,\n        \"samples\": [\n          \"A Corpus Study of Creating Rule-Based Enhanced Universal Dependencies for German</s>In this paper, we present a first attempt at enriching German Universal Dependencies UD treebanks with enhanced dependencies. Similarly to the converter for English Schuster and Manning, 2016 , we develop a rule-based system for deriving enhanced dependencies from the basic layer, covering three linguistic phenomena: relative clauses, coordination, and raising/control. For quality control, we manually correct or validate a set of 196 sentences, finding that around 90% of added relations are correct. Our data analysis reveals that difficulties arise mainly due to inconsistencies in the basic layer annotations. We show that the English system is in general applicable to German data, but that adapting to the particularities of the German treebanks and language increases precision and recall by up to 10%. Comparing the application of our converter on gold standard dependencies vs. automatic parses, we find that F1 drops by around 10% in the latter setting due to error propagation. Finally, an enhanced UD parser trained on a converted treebank performs poorly when evaluated against our annotations, indicating that more work remains to be done to create gold standard enhanced German treebanks.\",\n          \"Finding Arguments as Sequence Labeling in Discourse Parsing</s>This paper describes our system for the CoNLL-2016 Shared Task on Shallow Discourse Parsing on English. We adopt a cascaded framework consisting of nine components, among which six are casted as sequence labeling tasks and the remaining three are treated as classification problems. All our sequence labeling and classification models are implemented based on linear models with averaged perceptron training. Our feature sets are mostly borrowed from previous works. The main focus of our effort is to recall cases when Arg1 locates at sentences far before the connective phrase, with some yet limited success.\",\n          \"Social Media Unrest Prediction during the COVID-19 Pandemic: Neural Implicit Motive Pattern Recognition as Psychometric Signs of Severe Crises</s>The COVID-19 pandemic has caused international social tension and unrest. Besides the crisis itself, there are growing signs of rising conflict potential of societies around the world. Indicators of global mood changes are hard to detect and direct questionnaires suffer from social desirability biases. However, so-called implicit methods can reveal humans intrinsic desires from e.g. social media texts. We present psychologically validated social unrest predictors and replicate scalable and automated predictions, setting a new state of the art on a recent German shared task dataset. We employ this model to investigate a change of language towards social unrest during the COVID-19 pandemic by comparing established psychological predictors on samples of tweets from spring 2019 with spring 2020. The results show a significant increase of the conflict-indicating psychometrics. With this work, we demonstrate the applicability of automated NLP-based approaches to quantitative psychological research.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0b57c7fe-8988-4c0e-83bf-1d6fc205b27d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Automatic annotation of curricular language ta...</td>\n",
              "      <td>[Data Management and Generation, Information E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Recognizing Behavioral Factors while Driving: ...</td>\n",
              "      <td>[Audio Generation and Processing, Data Managem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Approaching Reflex Predictions as a Classifica...</td>\n",
              "      <td>[Multilingual NLP, Classification Applications...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FilipN@LT-EDI-ACL2022-Detecting signs of Depre...</td>\n",
              "      <td>[Classification Applications, Domain-specific ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Still on arguments and adjuncts: the status of...</td>\n",
              "      <td>[Parsing, Data Management and Generation, Low-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b57c7fe-8988-4c0e-83bf-1d6fc205b27d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0b57c7fe-8988-4c0e-83bf-1d6fc205b27d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0b57c7fe-8988-4c0e-83bf-1d6fc205b27d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c35b8f48-d650-47e3-b4c2-926341209481\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c35b8f48-d650-47e3-b4c2-926341209481')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c35b8f48-d650-47e3-b4c2-926341209481 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  Automatic annotation of curricular language ta...   \n",
              "1  Recognizing Behavioral Factors while Driving: ...   \n",
              "2  Approaching Reflex Predictions as a Classifica...   \n",
              "3  FilipN@LT-EDI-ACL2022-Detecting signs of Depre...   \n",
              "4  Still on arguments and adjuncts: the status of...   \n",
              "\n",
              "                                              labels  \n",
              "0  [Data Management and Generation, Information E...  \n",
              "1  [Audio Generation and Processing, Data Managem...  \n",
              "2  [Multilingual NLP, Classification Applications...  \n",
              "3  [Classification Applications, Domain-specific ...  \n",
              "4  [Parsing, Data Management and Generation, Low-...  "
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data[['text', 'labels']]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "c7EZvFja8s0Y"
      },
      "outputs": [],
      "source": [
        "all_labels_flat = [item for items in all_labels for item in items]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "s6d1mT0g8t-x"
      },
      "outputs": [],
      "source": [
        "num_categories = len(set(all_labels_flat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6pAJLEz8w19",
        "outputId": "fda40ab0-36aa-448f-fab8-6a5ee22170a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([155,  28,  72,  66,  65,  75,  41, 117,  34, 136,  64,  85, 143,\n",
              "        76,  68, 146,  57,  53, 100, 151,  11, 122, 147,  40,  39, 135,\n",
              "       118,  90,  70, 111,  82,   6, 114,   9, 144,  69,  79, 102,  67,\n",
              "       125,  73,  33,   0,  32, 153, 137,  44,  35, 108,  92,   2,  24,\n",
              "        62, 105,  91,  38, 107, 142, 129,  10,  18,  89, 131,  71,  31,\n",
              "       130,   4, 141,  25, 115, 109, 132,  88, 104,  80,  86,  46,  43,\n",
              "       116, 110,  27,  21,  52, 133, 140,  48, 145,  94,  51, 113,  60,\n",
              "        58,  93,  96,  23,  42, 119, 152,  78,  77,  61,  36,  50,  45,\n",
              "         5,   1, 126,  20,  83,  17,  15,  84,  29, 128, 112, 154,  13,\n",
              "        14, 106, 124,  99,  16,  63,  56,  26, 120,   7, 101, 121, 138,\n",
              "       103, 139, 148, 134, 150, 127,  95,  54,   3,  59,  47, 123,  30,\n",
              "       149,  87,  49,  74,  55,  98,  12,  19,   8,  81,  97,  37,  22])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Encode labels with LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit_transform(list(set(all_labels_flat)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "h0kmAKQp81dx"
      },
      "outputs": [],
      "source": [
        "le_name_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "CbfLpeRb895c"
      },
      "outputs": [],
      "source": [
        "all_encoded_labels = []\n",
        "for idx, row in data.iterrows():\n",
        "    labels = row['labels']\n",
        "    encoded_labels = [le_name_mapping[label] for label in labels]\n",
        "    all_encoded_labels.append(encoded_labels)\n",
        "\n",
        "data['encoded_labels'] = all_encoded_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "B980sGxe9Stb"
      },
      "outputs": [],
      "source": [
        "all_multi_hot_labels = []\n",
        "for idx, row in data.iterrows():\n",
        "    categorical_labels = row['encoded_labels']\n",
        "\n",
        "    # Convert categorical labels to multi-hot encoding\n",
        "    multi_hot_encoding = np.zeros(num_categories)\n",
        "    multi_hot_encoding[categorical_labels] = 1\n",
        "\n",
        "    all_multi_hot_labels.append(multi_hot_encoding)\n",
        "\n",
        "data['multi_hot_labels'] = all_multi_hot_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOi8snPx9dvo"
      },
      "source": [
        "## Convert data into Huggingface dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Nru7ORsg9ghw"
      },
      "outputs": [],
      "source": [
        "train_dataset = ds.dataset(pa.Table.from_pandas(data).to_batches())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36zaFWtG9xDr",
        "outputId": "8f003c66-acb4-43c8-9be3-0c320913be04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'labels', 'encoded_labels', 'multi_hot_labels'],\n",
              "    num_rows: 1050\n",
              "})"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Turn it into a dataset\n",
        "train_dataset = Dataset(pa.Table.from_pandas(data))\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD9rovgJ90XQ",
        "outputId": "029093c3-b906-4dc3-c271-abb865a8877e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'labels', 'encoded_labels', 'multi_hot_labels'],\n",
              "        num_rows: 1050\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Turn it into a dictionary (why?)\n",
        "dd = DatasetDict({\"train\":train_dataset})\n",
        "dd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "lmxvBrdO-EOJ"
      },
      "outputs": [],
      "source": [
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=True, truncation=True, max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "15236a4ea0494b23b213953052a0f641",
            "255c4936a41a41e4a7cf094feb9d6d73",
            "01915830565d45c7ba38a8d0066baf54",
            "a2cca20d4584409ba7908bffc1e0f9a8",
            "af38308015864c8a8a6c79fa37ea691c",
            "4b8aa5aad68649a8bdc974823496dacf",
            "db33af98cd9140c58a1ce283f37550de",
            "0c1b0e3422804770a94a872c4f262516",
            "293d06fa9d274c8183896bdb17beac23",
            "c585fca61c4e4812a5c01483a306467b",
            "f1b1aa589d8f4b15b97781a688c1751f"
          ]
        },
        "id": "BQYoGuJm-ia_",
        "outputId": "3012f717-745c-4d3e-f833-5581c99c3bd1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15236a4ea0494b23b213953052a0f641",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1050 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'labels', 'encoded_labels', 'multi_hot_labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1050\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets = dd.map(tokenize_function, batched=True)\n",
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QrwR1mj-uwa",
        "outputId": "18179309-fde4-472c-a190-e46f9deb9ed1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1050\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# remove unnecessary columns from dataset\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"text\", \"labels\", \"encoded_labels\"])\n",
        "# rename the label column to labels because the model expects the argument to be named as the latter\n",
        "# multi_hot_labels is now 'labels'\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"multi_hot_labels\", \"labels\")\n",
        "# set the format of the dataset to return PyTorch instead of lists\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "CIjd-SA_6kMZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMYg8NI3_kDt"
      },
      "source": [
        "# Training with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "Q05sryb9_mxy"
      },
      "outputs": [],
      "source": [
        "# create DataLoader objects to iterate over batches of data when training\n",
        "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=False, batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eomk0vUe_psU",
        "outputId": "cbf8af81-30ff-42dc-dcdc-72ff0a31912d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# get the model\n",
        "custom_model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
        "                                                           num_labels=num_categories\n",
        "                                                          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJb5qZ0M_r3W",
        "outputId": "47509e8b-c987-4372-fcf8-8633b3087dcd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=156, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loss function\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(custom_model.parameters(), lr=1e-5)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "custom_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLL3y8IcAoqL"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "C3PAbYimAqHC"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNkelnkVAsPG",
        "outputId": "585fa8f4-0f81-4fce-fbdc-d33b7540696a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: tensor(0.6833, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.6739, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.6667, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.6590, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.6494, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.6418, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.6353, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.6284, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.6204, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.6112, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.6059, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5989, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5992, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5903, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5824, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5817, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5747, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5699, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5687, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5616, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5571, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5559, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5511, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5440, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5384, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5380, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5381, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5368, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5230, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5250, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5264, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5189, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5151, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5100, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5125, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5063, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5045, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4986, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.5031, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4889, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4966, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4876, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4872, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4867, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4825, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4756, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4734, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4705, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4670, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4676, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4619, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4702, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4641, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4613, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4527, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4483, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4538, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4460, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4503, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4408, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4351, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4413, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4507, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4374, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4329, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4257, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4279, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4255, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4203, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4298, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4197, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4226, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4143, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4132, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4081, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4057, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4161, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4007, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4022, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4012, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.4019, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3969, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3948, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3886, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3954, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3937, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3874, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3855, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3858, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3820, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3796, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3828, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3755, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3762, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3716, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3678, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3638, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3647, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3612, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3670, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3590, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3524, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3557, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3606, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3505, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3558, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3499, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3485, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3431, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3517, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3422, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3302, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3328, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3311, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3376, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3369, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3384, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3325, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3228, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3436, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3260, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3210, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3171, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3133, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3137, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3118, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3253, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3107, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3100, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3120, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2985, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3091, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3057, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3065, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3154, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2963, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2966, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3010, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.3006, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2932, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2970, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2958, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2820, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2849, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2921, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2860, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2881, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2921, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2769, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2744, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2774, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2761, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2758, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2771, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2705, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2769, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2699, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2753, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2736, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2756, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2606, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2692, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2713, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2563, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2679, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2640, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2625, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2617, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2618, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2568, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2648, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2406, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2729, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2518, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2534, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2558, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2596, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2501, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2398, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2415, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2377, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2347, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2394, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2484, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2476, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2479, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2243, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2254, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2394, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2324, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2378, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2240, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2233, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2282, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2489, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2328, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2289, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2106, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2296, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2173, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2177, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2184, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2189, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2310, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2151, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2203, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2139, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2185, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2302, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2103, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2157, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2129, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2275, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2170, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2195, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2091, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2223, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2166, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2062, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2092, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2181, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2180, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2147, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2223, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2062, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2099, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2067, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2006, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2030, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1953, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1981, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2085, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1980, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1898, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1991, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2062, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1989, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2056, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1987, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2002, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1928, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2112, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2006, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1836, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1814, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1854, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1985, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1973, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1955, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1999, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1815, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2145, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1915, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1862, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1791, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1788, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1844, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1828, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2029, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1810, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1808, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1861, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1691, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1834, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1846, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1861, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.2007, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1805, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1775, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1830, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1860, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1843, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1816, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1831, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1677, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1676, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1867, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1738, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1755, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1892, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1684, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1644, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1702, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1749, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1765, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1755, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1669, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1751, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1712, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1771, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1788, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1827, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1658, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1739, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1765, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1573, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1812, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1726, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1827, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1720, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1776, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1704, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1774, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1490, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1656, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1735, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1764, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1757, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1668, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1537, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1602, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1565, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1511, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1582, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1766, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1757, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1729, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1429, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1415, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1685, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1591, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1635, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1493, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1517, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1569, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1833, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1636, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1601, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1377, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1642, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1457, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1472, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1501, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1508, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1704, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1465, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1579, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1506, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1520, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1747, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1464, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1589, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1559, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1721, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1567, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1620, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1504, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1690, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1619, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1486, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1529, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1618, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1644, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1558, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1690, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1525, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1589, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1535, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1482, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1506, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1437, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1478, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1601, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1469, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1361, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1495, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1621, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1443, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1559, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1515, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1488, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1458, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1681, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1560, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1361, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1315, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1368, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1514, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1497, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1514, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1600, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1373, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1782, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1443, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1413, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1347, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1345, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1415, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1365, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1666, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1369, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1397, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1436, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1259, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "loss: tensor(0.1417, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    custom_model.train()\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch['input_ids']\n",
        "        labels = batch['labels']\n",
        "        input_ids, labels_batch = input_ids.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = custom_model(input_ids, labels=labels_batch)  # Use labels directly for multi-label classification\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = outputs.loss\n",
        "\n",
        "        print(\"loss:\", loss)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKa2VYrOCnRp"
      },
      "source": [
        "## Create validation predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "06581d2f7fc6493c8e3524354544e203",
            "7c8616587f314855998292c4069fb05f",
            "8e7b47d1ae4042538eeaffe4067cb4ad",
            "d49857dee047498f9f756023ceaea820",
            "3a17f32b98bf4a66ad2081505e94fabc",
            "9ca5ff3920f3480a9b8ec83567f4553c",
            "8fee90d411064f2b8898bf6e4906a60a",
            "a996e179ac2b45ff99693821801c6454",
            "3287c765424b4f3e8a0cb1e7dbc7de84",
            "a4130d3231aa40eba8b2bb7f417e422c",
            "5c56b0b6cada42c3a7eaf6a2b9cb647b"
          ]
        },
        "id": "yKALm7ofClMX",
        "outputId": "2d8eeb88-5d80-4c33-992f-8fa67c9a1e23"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06581d2f7fc6493c8e3524354544e203",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/225 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# create validation dataloader\n",
        "val_df = pd.read_csv('val_doi.csv')\n",
        "val_df = val_df[['title', 'abstract', 'data_index']]\n",
        "val_df['text'] = [row['title'] + tokenizer.sep_token + (row['abstract'] or '')\n",
        "                    for index, row in val_df.iterrows()]\n",
        "val_data = val_df[['text']]\n",
        "val_dataset = ds.dataset(pa.Table.from_pandas(val_data).to_batches())\n",
        "val_dataset = Dataset(pa.Table.from_pandas(val_data))\n",
        "dd_val = DatasetDict({\"val\":val_dataset})\n",
        "tokenized_val = dd_val.map(tokenize_function, batched=True)\n",
        "# remove unnecessary columns from dataset\n",
        "tokenized_val = tokenized_val.remove_columns([\"text\"])\n",
        "# set the format of the dataset to return PyTorch instrad og lists\n",
        "tokenized_val.set_format(\"torch\")\n",
        "val_dataloader = DataLoader(tokenized_val[\"val\"], shuffle=False, batch_size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7kcXb9YDEW0"
      },
      "source": [
        "## Evaluation loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "iy9x_q_0DB84"
      },
      "outputs": [],
      "source": [
        "custom_model.eval()\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "for batch in val_dataloader:\n",
        "    input_ids = batch['input_ids']\n",
        "    input_ids = input_ids.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = custom_model(input_ids)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    predictions = torch.sigmoid(logits)\n",
        "    all_predictions.append(predictions.cpu().numpy())\n",
        "\n",
        "all_predictions = np.concatenate(all_predictions, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy81A14UJTRJ"
      },
      "source": [
        "## Defining N? Why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfgpQBLQJSjY",
        "outputId": "7558fb67-e2c0-4ea1-93d8-a4de635ee351"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1050"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len_labels = []\n",
        "\n",
        "# Data is the training set\n",
        "for label in data['labels'].values:\n",
        "    len_labels.append(len(label))\n",
        "\n",
        "len(len_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "F5dvhWdfJwqP"
      },
      "outputs": [],
      "source": [
        "n = int(round(np.average(len_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "ahe6Du77J2SV"
      },
      "outputs": [],
      "source": [
        "top_n_preds = []\n",
        "for pred in all_predictions:\n",
        "    top_n_preds.append(pred.argsort()[-n:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihnmlGCRKAD-",
        "outputId": "3c3c3726-1934-4d15-bad8-8d5283d2db90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'Abstract Meaning Representation (AMR)',\n",
              " 1: 'Abstractive Text Summarization',\n",
              " 2: 'Active Learning',\n",
              " 3: 'Adversarial Attacks and Robustness',\n",
              " 4: 'Adversarial Learning',\n",
              " 5: 'Anaphora Resolution',\n",
              " 6: 'Annotation Processes',\n",
              " 7: 'Argument Mining',\n",
              " 8: 'Aspect-Based SA (ABSA)',\n",
              " 9: 'Audio Generation and Processing',\n",
              " 10: 'Author Detection',\n",
              " 11: 'Authorship Verification',\n",
              " 12: 'Automatic Speech Recognition (ASR)',\n",
              " 13: 'Automatic Text Summarization',\n",
              " 14: 'Bias Detection',\n",
              " 15: 'Biases in NLP',\n",
              " 16: 'Bilingual Lexicon Induction (BLI)',\n",
              " 17: 'Biomedical NLP',\n",
              " 18: 'Chatbots',\n",
              " 19: 'Citation Analysis',\n",
              " 20: 'Claim Verification',\n",
              " 21: 'Classification Applications',\n",
              " 22: 'Commonsense Reasoning',\n",
              " 23: 'Community QA',\n",
              " 24: 'Constituency Parsing',\n",
              " 25: 'Coreference Resolution',\n",
              " 26: 'Cross-lingual Application',\n",
              " 27: 'Data Analysis',\n",
              " 28: 'Data Augmentation',\n",
              " 29: 'Data Management and Generation',\n",
              " 30: 'Data Preparation',\n",
              " 31: 'Data-to-Text Generation',\n",
              " 32: 'Dependency Parsing',\n",
              " 33: 'Dialogue State Tracking (DST)',\n",
              " 34: 'Dialogue Systems',\n",
              " 35: 'Discourse Analysis',\n",
              " 36: 'Discourse Parsing',\n",
              " 37: 'Document Layout Analysis (DLA)',\n",
              " 38: 'Document Summarization',\n",
              " 39: 'Domain-specific NLP',\n",
              " 40: 'Embeddings',\n",
              " 41: 'Emotion Detection',\n",
              " 42: 'Entity Linking',\n",
              " 43: 'Error Detection and Correction',\n",
              " 44: 'Ethics',\n",
              " 45: 'Evaluation Techniques',\n",
              " 46: 'Event Extraction',\n",
              " 47: 'Extractive Text Summarization',\n",
              " 48: 'Fake News Detection',\n",
              " 49: 'Fake Review Detection',\n",
              " 50: 'Few-shot Learning',\n",
              " 51: 'Figurative Language',\n",
              " 52: 'Finite State Machines',\n",
              " 53: 'Gender Bias',\n",
              " 54: 'Grammatical Error Correction (GEC)',\n",
              " 55: 'Graph Neural Networks (GNNs)',\n",
              " 56: 'Hate and Offensive Speech Detection',\n",
              " 57: 'Humor Detection',\n",
              " 58: 'Hypernymy Extraction',\n",
              " 59: 'Idiomatic Expressions',\n",
              " 60: 'Image Captioning',\n",
              " 61: 'Image and Video Processing',\n",
              " 62: 'Information Extraction',\n",
              " 63: 'Information Filtering',\n",
              " 64: 'Information Retrieval',\n",
              " 65: 'Intelligent Agents',\n",
              " 66: 'Intent Detection',\n",
              " 67: 'Knowledge Base QA',\n",
              " 68: 'Knowledge Graphs',\n",
              " 69: 'Knowledge Representation and Reasoning',\n",
              " 70: 'Language Change Analysis',\n",
              " 71: 'Large Language Models (LLMs)',\n",
              " 72: 'Latent Dirichlet Allocation (LDA)',\n",
              " 73: 'Learning Paradigms',\n",
              " 74: 'Link Prediction',\n",
              " 75: 'Long Form QA',\n",
              " 76: 'Long Short-Term Memory (LSTM) Models',\n",
              " 77: 'Low-resource Languages',\n",
              " 78: 'Lyrics Generation',\n",
              " 79: 'Machine Translation (MT)',\n",
              " 80: 'Mathematical QA',\n",
              " 81: 'Medical and Clinical NLP',\n",
              " 82: 'Metaphors',\n",
              " 83: 'Misinformation Detection',\n",
              " 84: 'Model Architectures',\n",
              " 85: 'Morphological Parsing',\n",
              " 86: 'Multi-agent Communication Systems',\n",
              " 87: 'Multihop Reasoning',\n",
              " 88: 'Multilabel Text Classification',\n",
              " 89: 'Multilingual NLP',\n",
              " 90: 'Multimodal Learning',\n",
              " 91: 'Multiple Choice QA (MCQA)',\n",
              " 92: 'NER for Nested Entities',\n",
              " 93: 'NLP for Bibliometrics and Scientometrics',\n",
              " 94: 'NLP for Finance',\n",
              " 95: 'NLP for Mental Health',\n",
              " 96: 'NLP for News and Media',\n",
              " 97: 'NLP for Social Media',\n",
              " 98: 'NLP for the Legal Domain',\n",
              " 99: 'Named Entity Recognition (NER)',\n",
              " 100: 'Narrative Plot in Storytelling',\n",
              " 101: 'Neural MT (NMT)',\n",
              " 102: 'Ontologies',\n",
              " 103: 'Ontology Construction',\n",
              " 104: 'Ontology Extension',\n",
              " 105: 'Open Domain Dialogue Systems',\n",
              " 106: 'Open-Domain QA',\n",
              " 107: 'Optical Character Recognition (OCR)',\n",
              " 108: 'Paraphrase and Rephrase Generation',\n",
              " 109: 'Parsing',\n",
              " 110: 'Part-of-Speech (POS) Tagging',\n",
              " 111: 'Personality Trait Prediction',\n",
              " 112: 'Plagiarism Detection',\n",
              " 113: 'Poetry Generation',\n",
              " 114: 'Prompt Engineering',\n",
              " 115: 'Question Answering (QA)',\n",
              " 116: 'Recommender Systems',\n",
              " 117: 'Recurrent Neural Networks (RNNs)',\n",
              " 118: 'Reinforcement Learning',\n",
              " 119: 'Relation Extraction',\n",
              " 120: 'Response Generation',\n",
              " 121: 'Rule-based MT (RBMT)',\n",
              " 122: 'Rumor Detection',\n",
              " 123: 'Sarcasm Detection',\n",
              " 124: 'Search Engines',\n",
              " 125: 'Semantic Change Analysis',\n",
              " 126: 'Semantic Parsing',\n",
              " 127: 'Semantic Role Labeling',\n",
              " 128: 'Semantic Web',\n",
              " 129: 'Sentence Embeddings',\n",
              " 130: 'Sentence Segmentation',\n",
              " 131: 'Sentiment Analysis (SA)',\n",
              " 132: 'Sign Language and Fingerspelling Recognition',\n",
              " 133: 'Stance Detection',\n",
              " 134: 'Statistical MT (SMT)',\n",
              " 135: 'Story Generation',\n",
              " 136: 'Supervised Learning',\n",
              " 137: 'Syntactic Parsing',\n",
              " 138: 'Table-to-Text Generation',\n",
              " 139: 'Taxonomy Construction',\n",
              " 140: 'Temporal Event Understanding',\n",
              " 141: 'Text Clustering',\n",
              " 142: 'Text Generation',\n",
              " 143: 'Text Preprocessing',\n",
              " 144: 'Text Segmentation',\n",
              " 145: 'Text Simplification',\n",
              " 146: 'Text Style Transfer',\n",
              " 147: 'Topic Modeling',\n",
              " 148: 'Transfer Learning',\n",
              " 149: 'Transformer Models',\n",
              " 150: 'Unsupervised Learning',\n",
              " 151: 'Video Captioning',\n",
              " 152: 'Visual QA (VQA)',\n",
              " 153: 'Word Embeddings',\n",
              " 154: 'Word Segmentation',\n",
              " 155: 'Word Sense Disambiguation (WSD)'}"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inverted mapping from label to class\n",
        "inv_le_name_mapping = {v: k for k, v in le_name_mapping.items()}\n",
        "inv_le_name_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "gLUE3UWJKA9h"
      },
      "outputs": [],
      "source": [
        "# Go from categorical labels back to the original textual labels\n",
        "all_text_labels = []\n",
        "for preds in top_n_preds:\n",
        "    text_labels = []\n",
        "    for cat in preds:\n",
        "        text_labels.append(inv_le_name_mapping[cat])\n",
        "    all_text_labels.append(text_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPaVFjtEKU4p"
      },
      "source": [
        "## Construct lists of level1, level2, level3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "bKCezX-3KSXl"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('train_doi.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "a-5JGpc3Kj8O"
      },
      "outputs": [],
      "source": [
        "# In this example, we will disregard the hierarchical structure of each level\n",
        "level1_labels = []\n",
        "level2_labels = []\n",
        "level3_labels = []\n",
        "\n",
        "for idx, row in data.iterrows():\n",
        "    level1 = ast.literal_eval(row['Level1'])\n",
        "    level1_labels.append(level1)\n",
        "\n",
        "    if type(row['Level2']) != float:\n",
        "        level2 = ast.literal_eval(row['Level2'])\n",
        "        level2_labels.append(level2)\n",
        "\n",
        "    if type(row['Level3']) != float:\n",
        "        level3 = ast.literal_eval(row['Level3'])\n",
        "        level3_labels.append(level3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "XfzViISeKnbS"
      },
      "outputs": [],
      "source": [
        "level1_labels_flat = [item for items in level1_labels for item in items]\n",
        "level1_labels_flat = list(set(level1_labels_flat))\n",
        "level2_labels_flat = [item for items in level1_labels for item in items]\n",
        "level2_labels_flat = list(set(level2_labels_flat))\n",
        "level3_labels_flat = [item for items in level1_labels for item in items]\n",
        "level3_labels_flat = list(set(level3_labels_flat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "xOIwkyALKwBk",
        "outputId": "7fad6663-0680-4f54-e9de-68c520623a98"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"val_df\",\n  \"rows\": 225,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 225,\n        \"samples\": [\n          \"Towards Understanding Sample Variance in Visually Grounded Language Generation: Evaluations and Observations\",\n          \"This is how we do it: Answer Reranking for Open-domain How Questions with Paragraph Vectors and Minimal Feature Engineering\",\n          \"Unbabel's Submission to the WMT2019 APE Shared Task: BERT-Based Encoder-Decoder for Automatic Post-Editing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 225,\n        \"samples\": [\n          \"A major challenge in visually grounded language generation is to build robust benchmark datasets and models that can generalize well in real-world settings. To do this, it is critical to ensure that our evaluation protocols are correct, and benchmarks are reliable. In this work, we set forth to design a set of experiments to understand an important but often ignored problem in visually grounded language generation: given that humans have different utilities and visual attention, how will the sample variance in multi-reference datasets affect the models' performance? Empirically, we study several multi-reference datasets and corresponding vision-and-language tasks. We show that it is of paramount importance to report variance in experiments; that humangenerated references could vary drastically in different datasets/tasks, revealing the nature of each task; that metric-wise, CIDEr has shown systematically larger variances than others. Our evaluations on reference-per-instance shed light on the design of reliable datasets in the future.\",\n          \"We present a simple yet powerful approach to non-factoid answer reranking whereby question-answer pairs are represented by concatenated distributed representation vectors and a multilayer perceptron is used to compute the score for an answer. Despite its simplicity, our approach achieves state-of-the-art performance on a public dataset of How questions, outperforming systems which employ sophisticated feature sets. We attribute this good performance to the use of paragraph instead of word vector representations and to the use of suitable data for training these representations.\",\n          \"This paper describes Unbabel's submission to the WMT2019 APE Shared Task for the English-German language pair. Following the recent rise of large, powerful, pretrained models, we adapt the BERT pretrained model to perform Automatic Post-Editing in an encoder-decoder framework. Analogously to dual-encoder architectures we develop a BERT-based encoder-decoder BED model in which a single pretrained BERT encoder receives both the source src and machine translation mt strings. Furthermore, we explore a conservativeness factor to constrain the APE system to perform fewer edits. As the official results show, when trained on a weighted combination of in-domain and artificial training data, our BED system with the conservativeness penalty improves significantly the translations of a strong Neural Machine Translation NMT system by \\u22120.78 and +1.23 in terms of TER and BLEU, respectively. Finally, our submission achieves a new state-of-the-art, exaequo, in English-German APE of NMT.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 417,\n        \"min\": 4,\n        \"max\": 1498,\n        \"num_unique_values\": 225,\n        \"samples\": [\n          1289,\n          558,\n          1342\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 225,\n        \"samples\": [\n          \"Towards Understanding Sample Variance in Visually Grounded Language Generation: Evaluations and Observations</s>A major challenge in visually grounded language generation is to build robust benchmark datasets and models that can generalize well in real-world settings. To do this, it is critical to ensure that our evaluation protocols are correct, and benchmarks are reliable. In this work, we set forth to design a set of experiments to understand an important but often ignored problem in visually grounded language generation: given that humans have different utilities and visual attention, how will the sample variance in multi-reference datasets affect the models' performance? Empirically, we study several multi-reference datasets and corresponding vision-and-language tasks. We show that it is of paramount importance to report variance in experiments; that humangenerated references could vary drastically in different datasets/tasks, revealing the nature of each task; that metric-wise, CIDEr has shown systematically larger variances than others. Our evaluations on reference-per-instance shed light on the design of reliable datasets in the future.\",\n          \"This is how we do it: Answer Reranking for Open-domain How Questions with Paragraph Vectors and Minimal Feature Engineering</s>We present a simple yet powerful approach to non-factoid answer reranking whereby question-answer pairs are represented by concatenated distributed representation vectors and a multilayer perceptron is used to compute the score for an answer. Despite its simplicity, our approach achieves state-of-the-art performance on a public dataset of How questions, outperforming systems which employ sophisticated feature sets. We attribute this good performance to the use of paragraph instead of word vector representations and to the use of suitable data for training these representations.\",\n          \"Unbabel's Submission to the WMT2019 APE Shared Task: BERT-Based Encoder-Decoder for Automatic Post-Editing</s>This paper describes Unbabel's submission to the WMT2019 APE Shared Task for the English-German language pair. Following the recent rise of large, powerful, pretrained models, we adapt the BERT pretrained model to perform Automatic Post-Editing in an encoder-decoder framework. Analogously to dual-encoder architectures we develop a BERT-based encoder-decoder BED model in which a single pretrained BERT encoder receives both the source src and machine translation mt strings. Furthermore, we explore a conservativeness factor to constrain the APE system to perform fewer edits. As the official results show, when trained on a weighted combination of in-domain and artificial training data, our BED system with the conservativeness penalty improves significantly the translations of a strong Neural Machine Translation NMT system by \\u22120.78 and +1.23 in terms of TER and BLEU, respectively. Finally, our submission achieves a new state-of-the-art, exaequo, in English-German APE of NMT.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "val_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-fdb0a206-b00d-4b05-a90c-062b8da65ece\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>data_index</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fast and Robust POS tagger for Arabic Tweets U...</td>\n",
              "      <td>Part-of-Speech POS tagging is a key step in ma...</td>\n",
              "      <td>1320</td>\n",
              "      <td>Fast and Robust POS tagger for Arabic Tweets U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SAJA at TRAC 2020 Shared Task: Transfer Learni...</td>\n",
              "      <td>This paper describes the participation of the ...</td>\n",
              "      <td>373</td>\n",
              "      <td>SAJA at TRAC 2020 Shared Task: Transfer Learni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who mentions whom? Recognizing political actor...</td>\n",
              "      <td>We show that it is straightforward to train a ...</td>\n",
              "      <td>160</td>\n",
              "      <td>Who mentions whom? Recognizing political actor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Association between declarative memory and lan...</td>\n",
              "      <td>Episodic memory and semantic memory are two su...</td>\n",
              "      <td>824</td>\n",
              "      <td>Association between declarative memory and lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Improving Users' Demographic Prediction via th...</td>\n",
              "      <td>In this paper, we improve microblog users' dem...</td>\n",
              "      <td>208</td>\n",
              "      <td>Improving Users' Demographic Prediction via th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>Do sentence embeddings capture discourse prope...</td>\n",
              "      <td>We introduce four tasks designed to determine ...</td>\n",
              "      <td>1163</td>\n",
              "      <td>Do sentence embeddings capture discourse prope...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>DUTH at SemEval-2021 Task 7: Is Conventional M...</td>\n",
              "      <td>This paper describes the approach that was dev...</td>\n",
              "      <td>1130</td>\n",
              "      <td>DUTH at SemEval-2021 Task 7: Is Conventional M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>Enhancing Drug-Drug Interaction Extraction fro...</td>\n",
              "      <td>We propose a novel neural method to extract dr...</td>\n",
              "      <td>292</td>\n",
              "      <td>Enhancing Drug-Drug Interaction Extraction fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>Terme-\\`a-LLOD: Simplifying the Conversion and...</td>\n",
              "      <td>In recent years, there has been increasing int...</td>\n",
              "      <td>47</td>\n",
              "      <td>Terme-\\`a-LLOD: Simplifying the Conversion and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>Incorporating Graph Attention Mechanism into K...</td>\n",
              "      <td>Knowledge Graph KG reasoning aims at finding r...</td>\n",
              "      <td>602</td>\n",
              "      <td>Incorporating Graph Attention Mechanism into K...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>225 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdb0a206-b00d-4b05-a90c-062b8da65ece')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fdb0a206-b00d-4b05-a90c-062b8da65ece button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fdb0a206-b00d-4b05-a90c-062b8da65ece');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9e1c47a1-fdd8-4473-8b7c-36c6d7e19bfe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e1c47a1-fdd8-4473-8b7c-36c6d7e19bfe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9e1c47a1-fdd8-4473-8b7c-36c6d7e19bfe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_545e4677-84f0-4d77-b482-ec371e35d9fc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('val_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_545e4677-84f0-4d77-b482-ec371e35d9fc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('val_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 title  \\\n",
              "0    Fast and Robust POS tagger for Arabic Tweets U...   \n",
              "1    SAJA at TRAC 2020 Shared Task: Transfer Learni...   \n",
              "2    Who mentions whom? Recognizing political actor...   \n",
              "3    Association between declarative memory and lan...   \n",
              "4    Improving Users' Demographic Prediction via th...   \n",
              "..                                                 ...   \n",
              "220  Do sentence embeddings capture discourse prope...   \n",
              "221  DUTH at SemEval-2021 Task 7: Is Conventional M...   \n",
              "222  Enhancing Drug-Drug Interaction Extraction fro...   \n",
              "223  Terme-\\`a-LLOD: Simplifying the Conversion and...   \n",
              "224  Incorporating Graph Attention Mechanism into K...   \n",
              "\n",
              "                                              abstract  data_index  \\\n",
              "0    Part-of-Speech POS tagging is a key step in ma...        1320   \n",
              "1    This paper describes the participation of the ...         373   \n",
              "2    We show that it is straightforward to train a ...         160   \n",
              "3    Episodic memory and semantic memory are two su...         824   \n",
              "4    In this paper, we improve microblog users' dem...         208   \n",
              "..                                                 ...         ...   \n",
              "220  We introduce four tasks designed to determine ...        1163   \n",
              "221  This paper describes the approach that was dev...        1130   \n",
              "222  We propose a novel neural method to extract dr...         292   \n",
              "223  In recent years, there has been increasing int...          47   \n",
              "224  Knowledge Graph KG reasoning aims at finding r...         602   \n",
              "\n",
              "                                                  text  \n",
              "0    Fast and Robust POS tagger for Arabic Tweets U...  \n",
              "1    SAJA at TRAC 2020 Shared Task: Transfer Learni...  \n",
              "2    Who mentions whom? Recognizing political actor...  \n",
              "3    Association between declarative memory and lan...  \n",
              "4    Improving Users' Demographic Prediction via th...  \n",
              "..                                                 ...  \n",
              "220  Do sentence embeddings capture discourse prope...  \n",
              "221  DUTH at SemEval-2021 Task 7: Is Conventional M...  \n",
              "222  Enhancing Drug-Drug Interaction Extraction fro...  \n",
              "223  Terme-\\`a-LLOD: Simplifying the Conversion and...  \n",
              "224  Incorporating Graph Attention Mechanism into K...  \n",
              "\n",
              "[225 rows x 4 columns]"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzsOYchVLEC6"
      },
      "source": [
        "## Add predictions to val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "T5Q361j3LBtJ"
      },
      "outputs": [],
      "source": [
        "level1_df = []\n",
        "level2_df = []\n",
        "level3_df = []\n",
        "\n",
        "for labels in all_text_labels:\n",
        "    row_level1 = []\n",
        "    row_level2 = []\n",
        "    row_level3 = []\n",
        "    for label in labels:\n",
        "        if label in level1_labels_flat:\n",
        "            row_level1.append(label)\n",
        "        elif label in level2_labels_flat:\n",
        "            row_level2.append(label)\n",
        "        elif label in level3_labels_flat:\n",
        "            row_level3.append(label)\n",
        "\n",
        "    level1_df.append(row_level1)\n",
        "    level2_df.append(row_level2)\n",
        "    level3_df.append(row_level3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "adLbg97JLLFS"
      },
      "outputs": [],
      "source": [
        "val_df['Level1_pred'] = level1_df\n",
        "val_df['Level2_pred'] = level2_df\n",
        "val_df['Level3_pred'] = level3_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "G1t1LuDcLZ9R"
      },
      "outputs": [],
      "source": [
        "val_df[['data_index','Level1_pred', 'Level2_pred', 'Level3_pred']].to_csv('predictions.csv')\n",
        "zipfile.ZipFile('predictions.zip', mode='w').write(\"predictions.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLXLjBECLdvu"
      },
      "source": [
        "## Evaluations test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "pxCabWBeLbBs"
      },
      "outputs": [],
      "source": [
        "zf = zipfile.ZipFile('predictions.zip')\n",
        "preds = pd.read_csv(zf.open('predictions.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "c_uGy7muLgwR"
      },
      "outputs": [],
      "source": [
        "truth = pd.read_csv('val_doi.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "jHExYc4ELkrn"
      },
      "outputs": [],
      "source": [
        "merged = truth.merge(preds, on='data_index', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "6DDxqmLQLnEW",
        "outputId": "64f3b511-314d-4763-9810-952f0f13338f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"merged\",\n  \"rows\": 225,\n  \"fields\": [\n    {\n      \"column\": \"acl_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 225,\n        \"samples\": [\n          \"2020.emnlp-main.708\",\n          \"N16-1154\",\n          \"W19-5413\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Level1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 192,\n        \"samples\": [\n          \"['Domain-specific NLP', 'Information Extraction', 'Classification Applications']\",\n          \"['Domain-specific NLP', 'Machine Translation (MT)', 'Information Extraction', 'Learning Paradigms', 'Model Architectures']\",\n          \"['Domain-specific NLP', 'Data Management and Generation']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Level2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 136,\n        \"samples\": [\n          \"['Data Preparation', 'Data Analysis', 'Multilabel Text Classification']\",\n          \"['Medical and Clinical NLP']\",\n          \"['Transformer Models', 'Hate and Offensive Speech Detection']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Level3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"['NLP for Social Media']\",\n          \"['Ontology Extension']\",\n          \"['Aspect-Based SA (ABSA)']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 225,\n        \"samples\": [\n          \"A major challenge in visually grounded language generation is to build robust benchmark datasets and models that can generalize well in real-world settings. To do this, it is critical to ensure that our evaluation protocols are correct, and benchmarks are reliable. In this work, we set forth to design a set of experiments to understand an important but often ignored problem in visually grounded language generation: given that humans have different utilities and visual attention, how will the sample variance in multi-reference datasets affect the models' performance? Empirically, we study several multi-reference datasets and corresponding vision-and-language tasks. We show that it is of paramount importance to report variance in experiments; that humangenerated references could vary drastically in different datasets/tasks, revealing the nature of each task; that metric-wise, CIDEr has shown systematically larger variances than others. Our evaluations on reference-per-instance shed light on the design of reliable datasets in the future.\",\n          \"We present a simple yet powerful approach to non-factoid answer reranking whereby question-answer pairs are represented by concatenated distributed representation vectors and a multilayer perceptron is used to compute the score for an answer. Despite its simplicity, our approach achieves state-of-the-art performance on a public dataset of How questions, outperforming systems which employ sophisticated feature sets. We attribute this good performance to the use of paragraph instead of word vector representations and to the use of suitable data for training these representations.\",\n          \"This paper describes Unbabel's submission to the WMT2019 APE Shared Task for the English-German language pair. Following the recent rise of large, powerful, pretrained models, we adapt the BERT pretrained model to perform Automatic Post-Editing in an encoder-decoder framework. Analogously to dual-encoder architectures we develop a BERT-based encoder-decoder BED model in which a single pretrained BERT encoder receives both the source src and machine translation mt strings. Furthermore, we explore a conservativeness factor to constrain the APE system to perform fewer edits. As the official results show, when trained on a weighted combination of in-domain and artificial training data, our BED system with the conservativeness penalty improves significantly the translations of a strong Neural Machine Translation NMT system by \\u22120.78 and +1.23 in terms of TER and BLEU, respectively. Finally, our submission achieves a new state-of-the-art, exaequo, in English-German APE of NMT.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 225,\n        \"samples\": [\n          \"https://aclanthology.org/2020.emnlp-main.708\",\n          \"https://aclanthology.org/N16-1154\",\n          \"https://aclanthology.org/W19-5413\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"publisher\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"European Language Resources Association (ELRA)\",\n          \"Association for Machine Translation in the Americas\",\n          \"Global Wordnet Association\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2016,\n        \"max\": 2022,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2016,\n          2020,\n          2022\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"May\",\n          \"October\",\n          \"June\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"booktitle\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 168,\n        \"samples\": [\n          \"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers\",\n          \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n          \"Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: Student Research Workshop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 225,\n        \"samples\": [\n          \"Zhu, Wanrong  and\\nWang, Xin  and\\nNarayana, Pradyumna  and\\nSone, Kazoo  and\\nBasu, Sugato  and\\nWang, William Yang\",\n          \"Bogdanova, Dasha  and\\nFoster, Jennifer\",\n          \"Lopes, Ant{\\\\'o}nio V.  and\\nFarajian, M. Amin  and\\nCorreia, Gon{\\\\c{c}}alo M.  and\\nTr{\\\\'e}nous, Jonay  and\\nMartins, Andr{\\\\'e} F. T.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 225,\n        \"samples\": [\n          \"Towards Understanding Sample Variance in Visually Grounded Language Generation: Evaluations and Observations\",\n          \"This is how we do it: Answer Reranking for Open-domain How Questions with Paragraph Vectors and Minimal Feature Engineering\",\n          \"Unbabel's Submission to the WMT2019 APE Shared Task: BERT-Based Encoder-Decoder for Automatic Post-Editing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doi\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 144,\n        \"samples\": [\n          \"10.18653/v1/W18-6021\",\n          \"10.18653/v1/2020.acl-main.713\",\n          \"10.26615/978-954-452-056-4_155\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"venue\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 148,\n        \"samples\": [\n          \"gamnlp\",\n          \"ccl\",\n          \"dmr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 417,\n        \"min\": 4,\n        \"max\": 1498,\n        \"num_unique_values\": 225,\n        \"samples\": [\n          1289,\n          558,\n          1342\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 65,\n        \"min\": 0,\n        \"max\": 224,\n        \"num_unique_values\": 225,\n        \"samples\": [\n          9,\n          184,\n          120\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Level1_pred\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"['Domain-specific NLP', 'Model Architectures', 'Low-resource Languages', 'Data Management and Generation']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Level2_pred\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"[]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Level3_pred\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"[]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "merged"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ed4c11d0-86a1-47cf-8987-c2c85c34dd5f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acl_id</th>\n",
              "      <th>Level1</th>\n",
              "      <th>Level2</th>\n",
              "      <th>Level3</th>\n",
              "      <th>abstract</th>\n",
              "      <th>url</th>\n",
              "      <th>publisher</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>booktitle</th>\n",
              "      <th>author</th>\n",
              "      <th>title</th>\n",
              "      <th>doi</th>\n",
              "      <th>venue</th>\n",
              "      <th>data_index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Level1_pred</th>\n",
              "      <th>Level2_pred</th>\n",
              "      <th>Level3_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L16-1238</td>\n",
              "      <td>['Text Preprocessing', 'Domain-specific NLP', ...</td>\n",
              "      <td>['Part-of-Speech (POS) Tagging', 'Data Prepara...</td>\n",
              "      <td>['NLP for Social Media']</td>\n",
              "      <td>Part-of-Speech POS tagging is a key step in ma...</td>\n",
              "      <td>https://aclanthology.org/L16-1238</td>\n",
              "      <td>European Language Resources Association (ELRA)</td>\n",
              "      <td>2016</td>\n",
              "      <td>May</td>\n",
              "      <td>Proceedings of the Tenth International Confere...</td>\n",
              "      <td>Albogamy, Fahad  and\\nRamsay, Allan</td>\n",
              "      <td>Fast and Robust POS tagger for Arabic Tweets U...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>L16</td>\n",
              "      <td>1320</td>\n",
              "      <td>0</td>\n",
              "      <td>['Domain-specific NLP', 'Model Architectures',...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020.trac-1.16</td>\n",
              "      <td>['Learning Paradigms', 'Domain-specific NLP', ...</td>\n",
              "      <td>['Transformer Models', 'Transfer Learning', 'H...</td>\n",
              "      <td>['NLP for Social Media']</td>\n",
              "      <td>This paper describes the participation of the ...</td>\n",
              "      <td>https://aclanthology.org/2020.trac-1.16</td>\n",
              "      <td>European Language Resources Association (ELRA)</td>\n",
              "      <td>2020</td>\n",
              "      <td>May</td>\n",
              "      <td>Proceedings of the Second Workshop on Trolling...</td>\n",
              "      <td>Tawalbeh, Saja  and\\nHammad, Mahmoud  and\\nAL-...</td>\n",
              "      <td>SAJA at TRAC 2020 Shared Task: Transfer Learni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>trac</td>\n",
              "      <td>373</td>\n",
              "      <td>1</td>\n",
              "      <td>['Domain-specific NLP', 'Model Architectures',...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020.parlaclarin-1.7</td>\n",
              "      <td>['Domain-specific NLP', 'Data Management and G...</td>\n",
              "      <td>['Data Preparation', 'Search Engines', 'Named ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We show that it is straightforward to train a ...</td>\n",
              "      <td>https://aclanthology.org/2020.parlaclarin-1.7</td>\n",
              "      <td>European Language Resources Association</td>\n",
              "      <td>2020</td>\n",
              "      <td>May</td>\n",
              "      <td>Proceedings of the Second ParlaCLARIN Workshop</td>\n",
              "      <td>Kerkvliet, Lennart  and\\nKamps, Jaap  and\\nMar...</td>\n",
              "      <td>Who mentions whom? Recognizing political actor...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>parlaclarin</td>\n",
              "      <td>160</td>\n",
              "      <td>2</td>\n",
              "      <td>['Domain-specific NLP', 'Model Architectures',...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020.paclic-1.39</td>\n",
              "      <td>['Data Management and Generation', 'Low-resour...</td>\n",
              "      <td>['Data Analysis']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Episodic memory and semantic memory are two su...</td>\n",
              "      <td>https://aclanthology.org/2020.paclic-1.39</td>\n",
              "      <td>Association for Computational Linguistics</td>\n",
              "      <td>2020</td>\n",
              "      <td>October</td>\n",
              "      <td>Proceedings of the 34th Pacific Asia Conferenc...</td>\n",
              "      <td>Xie, Chenwei  and\\nFeng, Yun  and\\nWang, Willi...</td>\n",
              "      <td>Association between declarative memory and lan...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>paclic</td>\n",
              "      <td>824</td>\n",
              "      <td>3</td>\n",
              "      <td>['Domain-specific NLP', 'Model Architectures',...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>D16-1143</td>\n",
              "      <td>['Data Management and Generation', 'Classifica...</td>\n",
              "      <td>['Data Preparation', 'Multilabel Text Classifi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>In this paper, we improve microblog users' dem...</td>\n",
              "      <td>https://aclanthology.org/D16-1143</td>\n",
              "      <td>Association for Computational Linguistics</td>\n",
              "      <td>2016</td>\n",
              "      <td>November</td>\n",
              "      <td>Proceedings of the 2016 Conference on Empirica...</td>\n",
              "      <td>Wang, Yuan  and\\nXiao, Yang  and\\nMa, Chao  an...</td>\n",
              "      <td>Improving Users' Demographic Prediction via th...</td>\n",
              "      <td>10.18653/v1/D16-1143</td>\n",
              "      <td>D16</td>\n",
              "      <td>208</td>\n",
              "      <td>4</td>\n",
              "      <td>['Domain-specific NLP', 'Model Architectures',...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed4c11d0-86a1-47cf-8987-c2c85c34dd5f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed4c11d0-86a1-47cf-8987-c2c85c34dd5f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed4c11d0-86a1-47cf-8987-c2c85c34dd5f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e86424ca-d2b3-45ff-9c75-8c8da73727b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e86424ca-d2b3-45ff-9c75-8c8da73727b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e86424ca-d2b3-45ff-9c75-8c8da73727b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                 acl_id                                             Level1  \\\n",
              "0              L16-1238  ['Text Preprocessing', 'Domain-specific NLP', ...   \n",
              "1        2020.trac-1.16  ['Learning Paradigms', 'Domain-specific NLP', ...   \n",
              "2  2020.parlaclarin-1.7  ['Domain-specific NLP', 'Data Management and G...   \n",
              "3      2020.paclic-1.39  ['Data Management and Generation', 'Low-resour...   \n",
              "4              D16-1143  ['Data Management and Generation', 'Classifica...   \n",
              "\n",
              "                                              Level2  \\\n",
              "0  ['Part-of-Speech (POS) Tagging', 'Data Prepara...   \n",
              "1  ['Transformer Models', 'Transfer Learning', 'H...   \n",
              "2  ['Data Preparation', 'Search Engines', 'Named ...   \n",
              "3                                  ['Data Analysis']   \n",
              "4  ['Data Preparation', 'Multilabel Text Classifi...   \n",
              "\n",
              "                     Level3  \\\n",
              "0  ['NLP for Social Media']   \n",
              "1  ['NLP for Social Media']   \n",
              "2                       NaN   \n",
              "3                       NaN   \n",
              "4                       NaN   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  Part-of-Speech POS tagging is a key step in ma...   \n",
              "1  This paper describes the participation of the ...   \n",
              "2  We show that it is straightforward to train a ...   \n",
              "3  Episodic memory and semantic memory are two su...   \n",
              "4  In this paper, we improve microblog users' dem...   \n",
              "\n",
              "                                             url  \\\n",
              "0              https://aclanthology.org/L16-1238   \n",
              "1        https://aclanthology.org/2020.trac-1.16   \n",
              "2  https://aclanthology.org/2020.parlaclarin-1.7   \n",
              "3      https://aclanthology.org/2020.paclic-1.39   \n",
              "4              https://aclanthology.org/D16-1143   \n",
              "\n",
              "                                        publisher  year     month  \\\n",
              "0  European Language Resources Association (ELRA)  2016       May   \n",
              "1  European Language Resources Association (ELRA)  2020       May   \n",
              "2         European Language Resources Association  2020       May   \n",
              "3       Association for Computational Linguistics  2020   October   \n",
              "4       Association for Computational Linguistics  2016  November   \n",
              "\n",
              "                                           booktitle  \\\n",
              "0  Proceedings of the Tenth International Confere...   \n",
              "1  Proceedings of the Second Workshop on Trolling...   \n",
              "2     Proceedings of the Second ParlaCLARIN Workshop   \n",
              "3  Proceedings of the 34th Pacific Asia Conferenc...   \n",
              "4  Proceedings of the 2016 Conference on Empirica...   \n",
              "\n",
              "                                              author  \\\n",
              "0                Albogamy, Fahad  and\\nRamsay, Allan   \n",
              "1  Tawalbeh, Saja  and\\nHammad, Mahmoud  and\\nAL-...   \n",
              "2  Kerkvliet, Lennart  and\\nKamps, Jaap  and\\nMar...   \n",
              "3  Xie, Chenwei  and\\nFeng, Yun  and\\nWang, Willi...   \n",
              "4  Wang, Yuan  and\\nXiao, Yang  and\\nMa, Chao  an...   \n",
              "\n",
              "                                               title                   doi  \\\n",
              "0  Fast and Robust POS tagger for Arabic Tweets U...                   NaN   \n",
              "1  SAJA at TRAC 2020 Shared Task: Transfer Learni...                   NaN   \n",
              "2  Who mentions whom? Recognizing political actor...                   NaN   \n",
              "3  Association between declarative memory and lan...                   NaN   \n",
              "4  Improving Users' Demographic Prediction via th...  10.18653/v1/D16-1143   \n",
              "\n",
              "         venue  data_index  Unnamed: 0  \\\n",
              "0          L16        1320           0   \n",
              "1         trac         373           1   \n",
              "2  parlaclarin         160           2   \n",
              "3       paclic         824           3   \n",
              "4          D16         208           4   \n",
              "\n",
              "                                         Level1_pred Level2_pred Level3_pred  \n",
              "0  ['Domain-specific NLP', 'Model Architectures',...          []          []  \n",
              "1  ['Domain-specific NLP', 'Model Architectures',...          []          []  \n",
              "2  ['Domain-specific NLP', 'Model Architectures',...          []          []  \n",
              "3  ['Domain-specific NLP', 'Model Architectures',...          []          []  \n",
              "4  ['Domain-specific NLP', 'Model Architectures',...          []          []  "
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "w-AEhnu5Lo9E"
      },
      "outputs": [],
      "source": [
        "merged = merged[['Level1', 'Level2', 'Level3', 'Level1_pred', 'Level2_pred', 'Level3_pred', 'data_index']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "EPs6KilaLw1A"
      },
      "outputs": [],
      "source": [
        "# Make flat list of truth label\n",
        "all_labels_truth = []\n",
        "for idx, row in merged.iterrows():\n",
        "    labels = []\n",
        "    level1 = ast.literal_eval(row['Level1'])\n",
        "    labels.append(level1)\n",
        "\n",
        "    if type(row['Level2']) != float:\n",
        "        level2 = ast.literal_eval(row['Level2'])\n",
        "        labels.append(level2)\n",
        "\n",
        "    if type(row['Level3']) != float:\n",
        "        level3 = ast.literal_eval(row['Level3'])\n",
        "        labels.append(level3)\n",
        "\n",
        "    labels_flat = [item for items in labels for item in items]\n",
        "\n",
        "    all_labels_truth.append(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "dalS8GJLL7ij"
      },
      "outputs": [],
      "source": [
        "merged['labels_truth'] = all_labels_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "TZS1GI1vL-_K"
      },
      "outputs": [],
      "source": [
        "# Make flat list of predicted label\n",
        "all_labels_pred = []\n",
        "for idx, row in merged.iterrows():\n",
        "    labels = []\n",
        "    level1 = ast.literal_eval(row['Level1_pred'])\n",
        "    labels.append(level1)\n",
        "\n",
        "    if type(row['Level2']) != float:\n",
        "        level2 = ast.literal_eval(row['Level2_pred'])\n",
        "        labels.append(level2)\n",
        "\n",
        "    if type(row['Level3']) != float:\n",
        "        level3 = ast.literal_eval(row['Level3_pred'])\n",
        "        labels.append(level3)\n",
        "\n",
        "    labels_flat = [item for items in labels for item in items]\n",
        "\n",
        "    all_labels_pred.append(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "xkq2p_UxMBgw"
      },
      "outputs": [],
      "source": [
        "merged['labels_pred'] = all_labels_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "l3O138FHMD35"
      },
      "outputs": [],
      "source": [
        "merged = merged[['labels_truth', 'labels_pred', 'data_index']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "dxj0hP9cMHQE"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "FZHgpEnMMJni"
      },
      "outputs": [],
      "source": [
        "# Step 1: Convert to binary array using MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "binary_labels = mlb.fit_transform(merged['labels_truth'].values)\n",
        "# Step 2: Convert predicted labels to binary array\n",
        "predicted_binary_labels = mlb.transform(merged['labels_pred'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssK9YuEsMOg0",
        "outputId": "cbe5a1fd-b8d2-4ca5-df89-c53b2401cf0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weighted-averaged Precision: 0.10843563629690797\n",
            "Weighted-averaged Recall: 0.28075970272502065\n",
            "Micro-averaged F1-score: 0.3221222169587873\n",
            "Macro-averaged F1-score: 0.01819955258937506\n",
            "Weighted-averaged F1-score: 0.155749033928054\n",
            "Samples-averaged F1-score: 0.31402221453201845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Evaluate using standard metrics\n",
        "precision_macro = precision_score(binary_labels, predicted_binary_labels, average='macro')\n",
        "recall_macro = recall_score(binary_labels, predicted_binary_labels, average='macro')\n",
        "precision_weighted = precision_score(binary_labels, predicted_binary_labels, average='weighted')\n",
        "recall_weighted = recall_score(binary_labels, predicted_binary_labels, average='weighted')\n",
        "f1_micro = f1_score(binary_labels, predicted_binary_labels, average='micro')\n",
        "f1_macro = f1_score(binary_labels, predicted_binary_labels, average='macro')\n",
        "f1_weighted = f1_score(binary_labels, predicted_binary_labels, average='weighted')\n",
        "f1_samples = f1_score(binary_labels, predicted_binary_labels, average='samples')\n",
        "\n",
        "print(f\"Weighted-averaged Precision: {precision_weighted}\")\n",
        "wandb.log({\"Weighted-averaged Precision\": precision_weighted})\n",
        "print(f\"Weighted-averaged Recall: {recall_weighted}\")\n",
        "wandb.log({\"Weighted-averaged Recall\": recall_weighted})\n",
        "print(f\"Micro-averaged F1-score: {f1_micro}\")\n",
        "print(f\"Macro-averaged F1-score: {f1_macro}\")\n",
        "wandb.log({\"Macro-averaged F1-score\": f1_macro})\n",
        "print(f\"Weighted-averaged F1-score: {f1_weighted}\")\n",
        "wandb.log({\"Weighted-averaged F1-score\": f1_weighted})\n",
        "print(f\"Samples-averaged F1-score: {f1_samples}\")\n",
        "wandb.log({\"Samples-averaged F1-score\": f1_samples})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "mxP_s6wrwBH_",
        "outputId": "a7aa9bad-2bde-49ea-98c6-46427ce9fea8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Macro-averaged F1-score</td><td>▁</td></tr><tr><td>Samples-averaged F1-score</td><td>▁</td></tr><tr><td>Weighted-averaged F1-score</td><td>▁</td></tr><tr><td>Weighted-averaged Precision</td><td>▁</td></tr><tr><td>Weighted-averaged Recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Macro-averaged F1-score</td><td>0.0182</td></tr><tr><td>Samples-averaged F1-score</td><td>0.31402</td></tr><tr><td>Weighted-averaged F1-score</td><td>0.15575</td></tr><tr><td>Weighted-averaged Precision</td><td>0.10844</td></tr><tr><td>Weighted-averaged Recall</td><td>0.28076</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">deepset/roberta-base-squad2</strong> at: <a href='https://wandb.ai/rosakun/forc3cl/runs/kemhaw5m' target=\"_blank\">https://wandb.ai/rosakun/forc3cl/runs/kemhaw5m</a><br> View project at: <a href='https://wandb.ai/rosakun/forc3cl' target=\"_blank\">https://wandb.ai/rosakun/forc3cl</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250216_124929-kemhaw5m/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01915830565d45c7ba38a8d0066baf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c1b0e3422804770a94a872c4f262516",
            "max": 1050,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_293d06fa9d274c8183896bdb17beac23",
            "value": 1050
          }
        },
        "06581d2f7fc6493c8e3524354544e203": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c8616587f314855998292c4069fb05f",
              "IPY_MODEL_8e7b47d1ae4042538eeaffe4067cb4ad",
              "IPY_MODEL_d49857dee047498f9f756023ceaea820"
            ],
            "layout": "IPY_MODEL_3a17f32b98bf4a66ad2081505e94fabc"
          }
        },
        "0c1b0e3422804770a94a872c4f262516": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15236a4ea0494b23b213953052a0f641": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_255c4936a41a41e4a7cf094feb9d6d73",
              "IPY_MODEL_01915830565d45c7ba38a8d0066baf54",
              "IPY_MODEL_a2cca20d4584409ba7908bffc1e0f9a8"
            ],
            "layout": "IPY_MODEL_af38308015864c8a8a6c79fa37ea691c"
          }
        },
        "255c4936a41a41e4a7cf094feb9d6d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b8aa5aad68649a8bdc974823496dacf",
            "placeholder": "​",
            "style": "IPY_MODEL_db33af98cd9140c58a1ce283f37550de",
            "value": "Map: 100%"
          }
        },
        "293d06fa9d274c8183896bdb17beac23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3287c765424b4f3e8a0cb1e7dbc7de84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a17f32b98bf4a66ad2081505e94fabc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b8aa5aad68649a8bdc974823496dacf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c56b0b6cada42c3a7eaf6a2b9cb647b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c8616587f314855998292c4069fb05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ca5ff3920f3480a9b8ec83567f4553c",
            "placeholder": "​",
            "style": "IPY_MODEL_8fee90d411064f2b8898bf6e4906a60a",
            "value": "Map: 100%"
          }
        },
        "8e7b47d1ae4042538eeaffe4067cb4ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a996e179ac2b45ff99693821801c6454",
            "max": 225,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3287c765424b4f3e8a0cb1e7dbc7de84",
            "value": 225
          }
        },
        "8fee90d411064f2b8898bf6e4906a60a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ca5ff3920f3480a9b8ec83567f4553c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2cca20d4584409ba7908bffc1e0f9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c585fca61c4e4812a5c01483a306467b",
            "placeholder": "​",
            "style": "IPY_MODEL_f1b1aa589d8f4b15b97781a688c1751f",
            "value": " 1050/1050 [00:00&lt;00:00, 3278.29 examples/s]"
          }
        },
        "a4130d3231aa40eba8b2bb7f417e422c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a996e179ac2b45ff99693821801c6454": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af38308015864c8a8a6c79fa37ea691c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c585fca61c4e4812a5c01483a306467b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d49857dee047498f9f756023ceaea820": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4130d3231aa40eba8b2bb7f417e422c",
            "placeholder": "​",
            "style": "IPY_MODEL_5c56b0b6cada42c3a7eaf6a2b9cb647b",
            "value": " 225/225 [00:00&lt;00:00, 2823.63 examples/s]"
          }
        },
        "db33af98cd9140c58a1ce283f37550de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1b1aa589d8f4b15b97781a688c1751f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
